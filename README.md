# Infraestrutura AWS com Terraform - Modular

Este projeto contÃ©m uma infraestrutura AWS modularizada usando Terraform, onde cada componente estÃ¡ organizado em sua prÃ³pria pasta para facilitar a manutenÃ§Ã£o e reutilizaÃ§Ã£o.

## Estrutura do Projeto

```
infrastructure-iac/
â”œâ”€â”€ main.tf                     # Arquivo principal que chama todos os mÃ³dulos
â”œâ”€â”€ variables.tf                # VariÃ¡veis principais do projeto
â”œâ”€â”€ outputs.tf                  # Outputs principais da infraestrutura
â”œâ”€â”€ modules/                    # Pasta contendo todos os mÃ³dulos
â”‚   â”œâ”€â”€ vpc/                    # MÃ³dulo VPC
â”‚   â”‚   â””â”€â”€ main.tf            # Variables, Resources e Outputs da VPC
â”‚   â”œâ”€â”€ subnets/                # MÃ³dulo Subnets
â”‚   â”‚   â””â”€â”€ main.tf            # Variables, Resources e Outputs das Subnets
â”‚   â”œâ”€â”€ internet-gateway/       # MÃ³dulo Internet Gateway
â”‚   â”‚   â””â”€â”€ main.tf            # Variables, Resources e Outputs do IGW
â”‚   â”œâ”€â”€ route-tables/           # MÃ³dulo Route Tables
â”‚   â”‚   â””â”€â”€ main.tf            # Variables, Resources e Outputs das Route Tables
â”‚   â”œâ”€â”€ security-groups/        # MÃ³dulo Security Groups
â”‚   â”‚   â””â”€â”€ main.tf            # Variables, Resources e Outputs dos Security Groups
â”‚   â”œâ”€â”€ ec2/                    # MÃ³dulo EC2
â”‚   â”‚   â””â”€â”€ main.tf            # Variables, Resources e Outputs das instÃ¢ncias EC2
â”‚   â”œâ”€â”€ s3/                     # MÃ³dulo S3
â”‚   â”‚   â””â”€â”€ main.tf            # Variables, Resources e Outputs dos buckets S3
â”‚   â””â”€â”€ load-balancer/          # MÃ³dulo Load Balancer
â”‚       â””â”€â”€ main.tf            # Variables, Resources e Outputs do ELB
```

## Recursos Criados

### VPC e Rede
- **VPC**: Rede virtual privada (10.0.0.0/24)
- **Subnets**: 
  - Subnet pÃºblica (10.0.0.0/25)
  - Subnet privada (10.0.0.128/25)
- **Internet Gateway**: Para acesso Ã  internet
- **Route Tables**: Tabelas de roteamento para subnets

### SeguranÃ§a
- **Security Groups**:
  - SG PÃºblico: Permite SSH (porta 22) de qualquer IP
  - SG Privado: Permite SSH apenas da VPC

### ComputaÃ§Ã£o
- **EC2 Instances**:
  - InstÃ¢ncia pÃºblica (com IP pÃºblico)
  - InstÃ¢ncia privada (apenas IP privado)
- **Load Balancer**: ELB clÃ¡ssico na subnet pÃºblica

### Armazenamento
- **S3 Buckets**:
  - **aej-public-bucket**: Bucket pÃºblico para website e processamento Excel
  - **aej-staging-bucket**: Dados brutos do pipeline ETL
  - **aej-trusted-bucket**: Dados limpos (colunas filtradas)
  - **aej-cured-bucket**: Dados refinados (apenas livros)

### Processamento de Dados
- **Lambda Functions**:
  - **excel-processor**: Processa arquivos Excel enviados ao S3
  - **staging-to-trusted-etl**: Filtra colunas especÃ­ficas dos dados brutos
  - **trusted-to-cured-etl**: Filtra apenas registros de livros

## Como Usar

### PrÃ©-requisitos
- Terraform instalado (>= 1.2)
- AWS CLI configurado com credenciais vÃ¡lidas
- Acesso Ã  AWS com permissÃµes adequadas

### ğŸ” ConfiguraÃ§Ã£o de Credenciais do Banco de Dados (IMPORTANTE!)

Este projeto utiliza **AWS Systems Manager Parameter Store** para armazenar credenciais de forma segura. As senhas sÃ£o criptografadas e **nunca sÃ£o versionadas no Git**.

#### ğŸ“‹ Passo a Passo

**1. Criar o arquivo `terraform.tfvars` (NÃƒO versionado)**

Na pasta `Codigos-IaC/`, crie o arquivo `terraform.tfvars`:

```bash
cd Codigos-IaC
nano terraform.tfvars  # ou use seu editor preferido
```

**2. Adicionar as credenciais do banco de dados**

Coloque o seguinte conteÃºdo no arquivo:

```hcl
# ========================================
# TERRAFORM VARIABLES - VALORES SENSÃVEIS
# ========================================
# âš ï¸  ATENÃ‡ÃƒO: Este arquivo NÃƒO deve ser versionado no Git!

# Credenciais do banco de dados MySQL
# Troque pelos valores reais do seu ambiente

db_user     = "root"                      # UsuÃ¡rio do MySQL
db_password = "SuaSenhaForteAqui@2024"    # Senha do MySQL
db_host     = "10.0.0.100"                # IP ou hostname do servidor MySQL
```

âš ï¸ **IMPORTANTE**: 
- Substitua os valores pelos dados **reais** do seu banco MySQL
- `db_user`: geralmente `root` ou usuÃ¡rio customizado
- `db_password`: senha forte e segura (mÃ­nimo 12 caracteres)
- `db_host`: IP privado da instÃ¢ncia MySQL (ex: `10.0.0.150`) ou hostname

**3. Verificar que o arquivo estÃ¡ protegido**

O arquivo `.gitignore` jÃ¡ estÃ¡ configurado para **nÃ£o versionar** o `terraform.tfvars`:

```bash
# Verificar que terraform.tfvars NÃƒO aparece
git status

# O arquivo deve estar listado em .gitignore
cat ../.gitignore | grep tfvars
```

**4. Como funciona a seguranÃ§a**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ terraform.tfvars (LOCAL - NÃƒO VERSION.) â”‚
â”‚ db_password = "SenhaDoBanco123"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Terraform lÃª
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWS Parameter Store (CRIPTOGRAFADO)     â”‚
â”‚ /aej/database/password â†’ SecureString   â”‚
â”‚ Criptografia: AWS KMS                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ EC2 acessa via IAM
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EC2 Privada (backup_script.sh)          â”‚
â”‚ aws ssm get-parameter --with-decryption â”‚
â”‚ Credenciais nunca aparecem no cÃ³digo!   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**5. Todas as credenciais configuradas**

O Parameter Store armazena todas as credenciais de forma segura:

| ParÃ¢metro | Tipo | Origem | DescriÃ§Ã£o |
|-----------|------|--------|-----------|
| `/aej/database/name` | String | Hardcoded | Nome do banco: `aej_hub` |
| `/aej/database/user` | String | `var.db_user` ğŸ” | UsuÃ¡rio MySQL (ex: `root`) |
| `/aej/database/password` | SecureString | `var.db_password` ğŸ” | Senha criptografada com KMS |
| `/aej/database/host` | String | `var.db_host` ğŸ” | IP/hostname do servidor MySQL |
| `/aej/backup/s3-backup-bucket` | String | DinÃ¢mico | Nome do bucket S3 de backup |

ğŸ” = **Valor vem do `terraform.tfvars` (nÃ£o versionado)**

**6. Alterando credenciais apÃ³s o deploy**

Se precisar alterar **qualquer credencial** depois do `terraform apply`:

```bash
# OpÃ§Ã£o 1: Via AWS CLI (alterar senha)
aws ssm put-parameter \
  --name "/aej/database/password" \
  --value "NovaSenhaForte123" \
  --type "SecureString" \
  --overwrite \
  --region us-east-1

# OpÃ§Ã£o 1b: Alterar usuÃ¡rio
aws ssm put-parameter \
  --name "/aej/database/user" \
  --value "admin_user" \
  --type "String" \
  --overwrite \
  --region us-east-1

# OpÃ§Ã£o 1c: Alterar host
aws ssm put-parameter \
  --name "/aej/database/host" \
  --value "10.0.0.200" \
  --type "String" \
  --overwrite \
  --region us-east-1

# OpÃ§Ã£o 2: Editar terraform.tfvars e aplicar novamente (RECOMENDADO)
nano terraform.tfvars  # Altere db_user, db_password ou db_host
terraform apply        # Terraform atualiza todos os parÃ¢metros alterados
```

**7. Verificar credenciais no Parameter Store**

```bash
# Ver todos os parÃ¢metros (sem mostrar valores)
aws ssm describe-parameters --region us-east-1

# Ver um parÃ¢metro especÃ­fico (descriptografado)
aws ssm get-parameter \
  --name "/aej/database/password" \
  --with-decryption \
  --query 'Parameter.Value' \
  --output text \
  --region us-east-1
```

#### âœ… Checklist de SeguranÃ§a

Antes de fazer `terraform apply`, confirme:

- âœ… Arquivo `terraform.tfvars` criado com senha forte
- âœ… Arquivo `terraform.tfvars` **NÃƒO** aparece em `git status`
- âœ… `.gitignore` contÃ©m `*.tfvars`
- âœ… Senha usa caracteres especiais, nÃºmeros e letras
- âœ… Senha tem pelo menos 12 caracteres

#### ğŸš« O QUE **NÃƒO** FAZER

âŒ **NUNCA** commite o arquivo `terraform.tfvars` no Git  
âŒ **NUNCA** coloque senhas diretamente no `infra__aej.tf`  
âŒ **NUNCA** compartilhe o `terraform.tfvars` via chat/email  
âŒ **NUNCA** use senhas fracas como `123456` ou `password`  

---

### Comandos BÃ¡sicos

1. **Inicializar o Terraform**:
   ```bash
   cd Codigos-IaC
   terraform init
   ```

2. **Validar configuraÃ§Ã£o**:
   ```bash
   terraform validate
   ```

3. **Ver o que serÃ¡ criado** (recomendado antes do apply):
   ```bash
   terraform plan
   ```

4. **Aplicar a infraestrutura**:
   ```bash
   terraform apply
   ```

5. **Destruir a infraestrutura**:
   ```bash
   terraform destroy
   ```

### CustomizaÃ§Ã£o

VocÃª pode customizar a infraestrutura editando as variÃ¡veis em `variables.tf` ou passando valores via linha de comando:

```bash
terraform apply -var="aws_region=us-west-2" -var="environment=prod"
```

## Vantagens da Estrutura Simplificada

1. **Simplicidade**: Cada mÃ³dulo tem apenas um arquivo, facilitando a navegaÃ§Ã£o
2. **ReutilizaÃ§Ã£o**: MÃ³dulos podem ser reutilizados em diferentes projetos
3. **Manutenibilidade**: Cada componente estÃ¡ isolado e pode ser atualizado independentemente
4. **Legibilidade**: CÃ³digo mais organizado e fÃ¡cil de entender
5. **Funcionalidade Completa**: Cada arquivo `main.tf` contÃ©m tudo necessÃ¡rio (variables, resources, outputs)

## MÃ³dulos Funcionais

Cada mÃ³dulo Ã© completamente funcional e autocontido em um Ãºnico arquivo `main.tf`, que inclui:
- **Variables**: DefiniÃ§Ãµes de variÃ¡veis de entrada
- **Resources**: Recursos da AWS a serem criados
- **Outputs**: Valores de saÃ­da do mÃ³dulo

### Exemplo de uso individual de um mÃ³dulo:

```hcl
module "vpc_example" {
  source = "./modules/vpc"
  
  vpc_cidr = "10.1.0.0/16"
  vpc_name = "my-custom-vpc"
}
```

## Outputs DisponÃ­veis

A infraestrutura expÃµe vÃ¡rios outputs Ãºteis que podem ser consumidos por outros projetos ou usados para referÃªncia:

- IDs de recursos (VPC, subnets, instÃ¢ncias, etc.)
- IPs das instÃ¢ncias
- DNS do Load Balancer
- IDs dos buckets S3

## Sistema de Processamento de Excel via Lambda e S3

Este projeto inclui uma funÃ§Ã£o Lambda que processa automaticamente arquivos Excel (.xlsx) enviados para o bucket S3.

### ğŸ“‹ Funcionalidades

- **Trigger AutomÃ¡tico**: O Lambda Ã© acionado automaticamente quando arquivos `.xlsx` sÃ£o enviados para a pasta `datasets/` no S3
- **Processamento AssÃ­ncrono**: Arquivos sÃ£o processados em background sem necessidade de intervenÃ§Ã£o
- **RelatÃ³rios JSON**: Gera relatÃ³rios de processamento na pasta `outputs/` do bucket
- **Logs Detalhados**: CloudWatch mantÃ©m logs de todas as execuÃ§Ãµes

### ğŸš€ Como Usar

#### 1. ApÃ³s o Deploy da Infraestrutura

Execute o Terraform para criar todos os recursos:

```bash
cd Codigos-IaC
terraform init
terraform apply -auto-approve
```

#### 2. Obter InformaÃ§Ãµes do Bucket

ApÃ³s o deploy, veja as informaÃ§Ãµes importantes:

```bash
terraform output
```

VocÃª verÃ¡ informaÃ§Ãµes como:
- `s3_bucket_name`: Nome do bucket S3 criado
- `excel_lambda_function_name`: Nome da funÃ§Ã£o Lambda
- `excel_processing_instructions`: InstruÃ§Ãµes de uso
- `s3_website_endpoint`: Endpoint pÃºblico do bucket

#### 3. Enviar Arquivos Excel para Processamento

**Usando AWS CLI:**

```bash
# Enviar um Ãºnico arquivo
aws s3 cp seu_arquivo.xlsx s3://aej-public-bucket-XXXXXX/datasets/

# Enviar mÃºltiplos arquivos
aws s3 cp arquivo1.xlsx s3://aej-public-bucket-XXXXXX/datasets/
aws s3 cp arquivo2.xlsx s3://aej-public-bucket-XXXXXX/datasets/

# Enviar uma pasta inteira
aws s3 cp ./meus_excels/ s3://aej-public-bucket-XXXXXX/datasets/ --recursive
```

**Usando Console AWS:**
1. Acesse o S3 Console
2. Navegue atÃ© o bucket `aej-public-bucket-XXXXXX`
3. Entre na pasta `datasets/`
4. Clique em "Upload" e selecione seus arquivos `.xlsx`

#### 4. Verificar os Resultados

**Listar arquivos processados:**

```bash
# Ver relatÃ³rios gerados
aws s3 ls s3://aej-public-bucket-XXXXXX/outputs/

# Baixar um relatÃ³rio especÃ­fico
aws s3 cp s3://aej-public-bucket-XXXXXX/outputs/processing_report_2025-10-19_21-33-09.json .

# Baixar todos os resultados
aws s3 cp s3://aej-public-bucket-XXXXXX/outputs/ ./resultados/ --recursive
```

**Ver logs da execuÃ§Ã£o:**

```bash
# Listar Ãºltimas execuÃ§Ãµes do Lambda
aws logs describe-log-streams \
  --log-group-name "/aws/lambda/excel-processor-terraform" \
  --order-by LastEventTime \
  --descending \
  --max-items 5

# Ver logs de uma execuÃ§Ã£o especÃ­fica
aws logs filter-log-events \
  --log-group-name "/aws/lambda/excel-processor-terraform" \
  --start-time <timestamp_em_ms>
```

#### 5. Estrutura de Pastas no S3

```
s3://aej-public-bucket-XXXXXX/
â”œâ”€â”€ datasets/              # â† Coloque seus arquivos .xlsx aqui
â”‚   â”œâ”€â”€ arquivo1.xlsx
â”‚   â”œâ”€â”€ arquivo2.xlsx
â”‚   â””â”€â”€ tabelao_tratado.xlsx
â””â”€â”€ outputs/               # â† RelatÃ³rios processados aparecem aqui
    â”œâ”€â”€ processing_report_2025-10-19_21-29-53.json
    â””â”€â”€ processing_report_2025-10-19_21-33-09.json
```

### ğŸ”§ Arquivos do Lambda

- **`excel_processor_lambda.py`**: CÃ³digo Python da funÃ§Ã£o Lambda
- **`excel_processor_lambda.zip`**: Pacote ZIP criado automaticamente pelo Terraform

### âš™ï¸ ConfiguraÃ§Ãµes Importantes

**Recursos do Lambda:**
- Runtime: Python 3.9
- MemÃ³ria: 3008 MB (mÃ¡ximo disponÃ­vel)
- Timeout: 900 segundos (15 minutos)
- Trigger: S3 ObjectCreated em `datasets/*.xlsx`

**PermissÃµes:**
- Usa `LabRole` existente no AWS Labs
- Acesso de leitura/escrita no bucket S3
- Logs no CloudWatch

### ğŸ§¹ Limpeza e Destroy

**Importante**: Antes de destruir a infraestrutura, esvazie o bucket S3:

```bash
# Remover todos os arquivos do bucket
aws s3 rm s3://aej-public-bucket-XXXXXX --recursive

# Depois destruir a infraestrutura
terraform destroy -auto-approve
```

**Ou configure force_destroy no Terraform** (opcional):

No arquivo `infra__aej.tf`, adicione `force_destroy = true` no recurso do bucket:

```hcl
resource "aws_s3_bucket" "aej_public" {
  bucket        = "aej-public-bucket-${random_id.bucket_suffix.hex}"
  force_destroy = true  # â† Remove automaticamente objetos no destroy
}
```

âš ï¸ **AtenÃ§Ã£o**: Com `force_destroy = true`, todos os arquivos serÃ£o deletados automaticamente ao executar `terraform destroy`.

### ğŸ“Š Exemplo de RelatÃ³rio Gerado

```json
{
  "timestamp": "2025-10-19_21-33-09",
  "trigger_file": "datasets/tabelao_tratado.xlsx",
  "total_excel_files": 2,
  "excel_files_list": [
    "datasets/teste.xlsx",
    "datasets/tabelao_tratado.xlsx"
  ],
  "status": "detected",
  "message": "Excel files detected - ready for processing"
}
```

### ğŸ› Troubleshooting

**Problema**: Lambda nÃ£o estÃ¡ sendo acionado
- Verifique se o arquivo tem extensÃ£o `.xlsx`
- Confirme que estÃ¡ enviando para a pasta `datasets/`
- Verifique os logs no CloudWatch

**Problema**: Erro de permissÃ£o ao fazer destroy
- Execute: `aws s3 rm s3://seu-bucket --recursive`
- Depois execute: `terraform destroy`

**Problema**: Arquivo muito grande (timeout)
- O timeout estÃ¡ configurado para 15 minutos (mÃ¡ximo)
- Para arquivos gigantes, considere aumentar recursos ou dividir o arquivo

---

## Pipeline ETL Automatizado (Staging â†’ Trusted â†’ Cured)

Este projeto inclui um pipeline ETL completo e automatizado com trÃªs estÃ¡gios de processamento de dados.

### ğŸ“Š Arquitetura do Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      Lambda 1       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      Lambda 2       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STAGING   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚   TRUSTED   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚    CURED    â”‚
â”‚ (dados raw) â”‚   Filtra Colunas    â”‚ (dados      â”‚   Filtra Livros     â”‚ (livros     â”‚
â”‚             â”‚   Preenche null     â”‚  limpos)    â”‚   Preenche null     â”‚  apenas)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     CSV/XLSX                            CSV                                  CSV
```

### ğŸ”„ EstÃ¡gios do Pipeline

#### **EstÃ¡gio 1: STAGING (Dados Brutos)**
Armazena dados originais sem processamento.

#### **EstÃ¡gio 2: TRUSTED (Dados Limpos)**
**Lambda**: `staging-to-trusted-etl`

**TransformaÃ§Ãµes aplicadas:**
- Filtra **apenas** as seguintes colunas:
  - `data`
  - `dia da semana`
  - `feriado`
  - `product_category_name`
  - `seller_city`
  - `seller_state`
  - `quantidade`
  - `obra vendida`
  - `valor pago`
  - `forma de pagamento`
- Preenche campos vazios com `null`
- Normaliza nomes de colunas (case-insensitive)

#### **EstÃ¡gio 3: CURED (Dados Refinados)**
**Lambda**: `trusted-to-cured-etl`

**TransformaÃ§Ãµes aplicadas:**
- MantÃ©m **apenas** registros onde `product_category_name` contÃ©m:
  - `livro`
  - `book`
  - `literatura`
- Remove todas as outras categorias
- MantÃ©m preenchimento de `null` para campos vazios
- Gera estatÃ­sticas de processamento

### ğŸš€ Como Usar o Pipeline ETL

#### 1. **Enviar Dados Brutos ao Staging**

```bash
# Enviar arquivo CSV
aws s3 cp meus_dados.csv s3://aej-staging-bucket-XXXXXX/

# Enviar mÃºltiplos arquivos
aws s3 cp ./dados/ s3://aej-staging-bucket-XXXXXX/ --recursive --exclude "*" --include "*.csv"
```

âš ï¸ **Importante**: Use arquivos **CSV** para melhor compatibilidade. Excel (.xlsx) requer layer com pandas.

#### 2. **Aguardar Processamento AutomÃ¡tico**

O pipeline Ã© totalmente automÃ¡tico:

1. **Lambda 1** detecta arquivo no Staging â†’ processa â†’ salva no Trusted
2. **Lambda 2** detecta arquivo no Trusted â†’ processa â†’ salva no Cured

```bash
# Monitorar logs em tempo real
aws logs tail /aws/lambda/staging-to-trusted-etl --follow
aws logs tail /aws/lambda/trusted-to-cured-etl --follow
```

#### 3. **Baixar Dados Processados**

```bash
# Listar arquivos processados
aws s3 ls s3://aej-trusted-bucket-XXXXXX/trusted/
aws s3 ls s3://aej-cured-bucket-XXXXXX/cured/

# Baixar dados limpos (todas colunas filtradas)
aws s3 cp s3://aej-trusted-bucket-XXXXXX/trusted/ ./dados_trusted/ --recursive

# Baixar dados refinados (apenas livros)
aws s3 cp s3://aej-cured-bucket-XXXXXX/cured/ ./dados_cured/ --recursive
```

### ğŸ“ Estrutura de Arquivos nos Buckets

```
ğŸ“¦ aej-staging-bucket-XXXXXX/
â””â”€â”€ vendas_2024.csv                    # Dados originais

ğŸ“¦ aej-trusted-bucket-XXXXXX/
â””â”€â”€ trusted/
    â””â”€â”€ vendas_2024_trusted_20251019_143022.csv   # Colunas filtradas

ğŸ“¦ aej-cured-bucket-XXXXXX/
â””â”€â”€ cured/
    â””â”€â”€ vendas_2024_cured_20251019_143025.csv     # Apenas livros
```

### ğŸ“‹ Exemplo de TransformaÃ§Ã£o

**Entrada (Staging):**
```csv
data,dia da semana,feriado,product_category_name,seller_city,quantidade,outra_coluna
2024-01-01,Segunda,Sim,livros_tecnicos,SÃ£o Paulo,5,valor_ignorado
2024-01-02,TerÃ§a,NÃ£o,eletronicos,Rio de Janeiro,3,outro_valor
2024-01-03,Quarta,NÃ£o,livros_ficcao,Curitiba,2,mais_dados
```

**SaÃ­da Trusted (colunas filtradas):**
```csv
data,dia da semana,feriado,product_category_name,seller_city,seller_state,quantidade,obra vendida,valor pago,forma de pagamento
2024-01-01,Segunda,Sim,livros_tecnicos,SÃ£o Paulo,null,5,null,null,null
2024-01-02,TerÃ§a,NÃ£o,eletronicos,Rio de Janeiro,null,3,null,null,null
2024-01-03,Quarta,NÃ£o,livros_ficcao,Curitiba,null,2,null,null,null
```

**SaÃ­da Cured (apenas livros):**
```csv
data,dia da semana,feriado,product_category_name,seller_city,seller_state,quantidade,obra vendida,valor pago,forma de pagamento
2024-01-01,Segunda,Sim,livros_tecnicos,SÃ£o Paulo,null,5,null,null,null
2024-01-03,Quarta,NÃ£o,livros_ficcao,Curitiba,null,2,null,null,null
```

### âš™ï¸ ConfiguraÃ§Ãµes dos Lambdas ETL

| Lambda | MemÃ³ria | Timeout | Trigger | Output |
|--------|---------|---------|---------|--------|
| staging-to-trusted | 512 MB | 5 min | S3 `.csv` no Staging | Trusted bucket |
| trusted-to-cured | 512 MB | 5 min | S3 `.csv` no Trusted | Cured bucket |

### ğŸ” Monitoramento e Logs

**Ver execuÃ§Ãµes recentes:**
```bash
# Listar streams de log
aws logs describe-log-streams \
  --log-group-name "/aws/lambda/staging-to-trusted-etl" \
  --order-by LastEventTime \
  --descending \
  --max-items 5

# Filtrar logs por perÃ­odo
aws logs filter-log-events \
  --log-group-name "/aws/lambda/trusted-to-cured-etl" \
  --start-time $(date -d '1 hour ago' +%s)000
```

**Logs incluem:**
- Arquivo de origem processado
- Colunas encontradas e mapeadas
- NÃºmero de linhas processadas
- EstatÃ­sticas (total, aceitas, descartadas)
- LocalizaÃ§Ã£o do arquivo de saÃ­da

### ğŸ§¹ Limpeza dos Buckets ETL

Antes de destruir a infraestrutura:

```bash
# Esvaziar todos os buckets ETL
aws s3 rm s3://aej-staging-bucket-XXXXXX --recursive
aws s3 rm s3://aej-trusted-bucket-XXXXXX --recursive
aws s3 rm s3://aej-cured-bucket-XXXXXX --recursive

# Depois destruir
terraform destroy -auto-approve
```

**Ou configure `force_destroy = true`** (jÃ¡ configurado por padrÃ£o nos buckets ETL).

### ğŸ› Troubleshooting ETL

**Problema**: Lambda nÃ£o estÃ¡ processando
- Verifique se o arquivo Ã© `.csv` (Excel requer layer pandas)
- Confirme que enviou para o bucket correto (staging)
- Verifique logs no CloudWatch

**Problema**: Colunas nÃ£o encontradas
- O Lambda normaliza nomes (case-insensitive)
- Verifique se as colunas existem no CSV original
- Veja logs para mapeamento de colunas

**Problema**: Nenhum livro no Cured
- Verifique se `product_category_name` contÃ©m 'livro', 'book' ou 'literatura'
- Veja estatÃ­sticas nos logs do Lambda

**Problema**: Arquivo muito grande
- Aumente `timeout` e `memory_size` dos Lambdas no Terraform
- Considere dividir arquivos grandes em chunks menores

### ğŸ’¡ Dicas de Uso

1. **Use CSV em vez de Excel** para melhor performance e compatibilidade
2. **Monitore os logs** durante o primeiro processamento para validar mapeamento de colunas
3. **Teste com arquivo pequeno** primeiro para validar o pipeline
4. **Revise os outputs** do Terraform para ver nomes dos buckets criados

---
