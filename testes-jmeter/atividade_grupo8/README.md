# ğŸ§ª Testes de Performance JMeter - Grupo 8 - PI

## ğŸ“‹ DescriÃ§Ã£o dos Testes

Este diretÃ³rio contÃ©m 3 projetos de teste JMeter para anÃ¡lise de performance da aplicaÃ§Ã£o de vendas de livros.

### Teste A - POST com JWT Authentication (50 users/sec)
- **Arquivo:** `teste_a_post_jwt.jmx`
- **Objetivo:** Testar endpoint POST que recebe token JWT
- **Carga:** 50 usuÃ¡rios por segundo
- **DuraÃ§Ã£o:** 60 segundos
- **Endpoints testados:**
  - `POST /api/auth/login` - AutenticaÃ§Ã£o e obtenÃ§Ã£o do JWT
  - `POST /api/pedidos` - CriaÃ§Ã£o de pedido com JWT no header

### Teste B - GET Endpoints (50 users/sec)
- **Arquivo:** `teste_b_get_endpoints.jmx`
- **Objetivo:** Testar endpoints GET da API
- **Carga:** 50 usuÃ¡rios por segundo
- **DuraÃ§Ã£o:** 60 segundos
- **Endpoints testados:**
  - `GET /api/livros` - Listar todos os livros
  - `GET /api/livros/1` - Buscar livro por ID
  - `GET /api/categorias` - Listar categorias
  - `GET /api/vendas` - Listar vendas

### Teste C - Frontend via Nginx (20 users/sec)
- **Arquivo:** `teste_c_frontend_nginx.jmx`
- **Objetivo:** Testar pÃ¡gina do Frontend com todas as requisiÃ§Ãµes
- **Carga:** 20 usuÃ¡rios por segundo
- **DuraÃ§Ã£o:** 60 segundos
- **RequisiÃ§Ãµes testadas:**
  - `GET /` - PÃ¡gina HTML principal
  - `GET /assets/css/main.css` - CSS
  - `GET /assets/js/main.js` - JavaScript
  - `GET /favicon.ico` - Favicon
  - `AJAX GET /api/livros` - Chamada API
  - `AJAX GET /api/categorias` - Chamada API
  - `AJAX GET /api/dashboard/stats` - Chamada API

---

## ğŸ”§ PrÃ©-requisitos

1. **Apache JMeter 5.6+** instalado
2. **Java 8+** instalado
3. VariÃ¡vel de ambiente `JMETER_HOME` configurada

```powershell
# Windows PowerShell
$env:JMETER_HOME = "C:\apache-jmeter-5.6.3"

# Linux/Mac
export JMETER_HOME=/opt/apache-jmeter-5.6.3
```

---

## ğŸš€ Como Executar

### OpÃ§Ã£o 1: Script PowerShell (Recomendado para Windows)

```powershell
# Executar todos os testes
.\executar_testes.ps1

# Executar apenas o teste A
.\executar_testes.ps1 -Teste a

# Executar apenas o teste B
.\executar_testes.ps1 -Teste b

# Executar apenas o teste C
.\executar_testes.ps1 -Teste c

# Especificar caminho do JMeter
.\executar_testes.ps1 -JMeterHome "C:\apache-jmeter-5.6.3"
```

### OpÃ§Ã£o 2: Script BAT (Windows)

```cmd
executar_todos_testes.bat
```

### OpÃ§Ã£o 3: Script Bash (Linux/Mac)

```bash
chmod +x executar_todos_testes.sh
./executar_todos_testes.sh
```

### OpÃ§Ã£o 4: Linha de Comando JMeter (Manual)

```powershell
# Teste A
& "$env:JMETER_HOME\bin\jmeter.bat" -n -t teste_a_post_jwt.jmx -l results/teste_a/results.jtl -e -o results/teste_a/dashboard

# Teste B
& "$env:JMETER_HOME\bin\jmeter.bat" -n -t teste_b_get_endpoints.jmx -l results/teste_b/results.jtl -e -o results/teste_b/dashboard

# Teste C
& "$env:JMETER_HOME\bin\jmeter.bat" -n -t teste_c_frontend_nginx.jmx -l results/teste_c/results.jtl -e -o results/teste_c/dashboard
```

---

## ğŸ“Š Resultados Gerados

ApÃ³s a execuÃ§Ã£o, os seguintes arquivos sÃ£o gerados:

```
results/
â”œâ”€â”€ teste_a/
â”‚   â”œâ”€â”€ dashboard/           # Dashboard HTML interativo
â”‚   â”‚   â”œâ”€â”€ index.html       # PÃ¡gina principal do dashboard
â”‚   â”‚   â”œâ”€â”€ content/         # GrÃ¡ficos e relatÃ³rios
â”‚   â”‚   â””â”€â”€ statistics.json  # Dados estatÃ­sticos
â”‚   â”œâ”€â”€ results.jtl          # Resultados raw
â”‚   â”œâ”€â”€ aggregate_report.csv # Aggregate Report em CSV
â”‚   â””â”€â”€ jmeter.log           # Log de execuÃ§Ã£o
â”œâ”€â”€ teste_b/
â”‚   â””â”€â”€ (mesma estrutura)
â””â”€â”€ teste_c/
    â””â”€â”€ (mesma estrutura)
```

### I. Dashboard HTML

O Dashboard Ã© gerado automaticamente via CLI com a flag `-e -o`:
- Abra `results/teste_X/dashboard/index.html` no navegador
- ContÃ©m grÃ¡ficos de Response Time, Throughput, Erros, etc.

### II. Aggregate Report CSV

O Aggregate Report Ã© exportado automaticamente para CSV com as seguintes mÃ©tricas:
- Label (nome do sampler)
- \# Samples (quantidade de requisiÃ§Ãµes)
- Average (tempo mÃ©dio de resposta em ms)
- Median (mediana)
- 90%, 95%, 99% Line (percentis)
- Min/Max (tempo mÃ­nimo e mÃ¡ximo)
- Error % (percentual de erros)
- Throughput (requisiÃ§Ãµes por segundo)
- KB/sec (bytes recebidos/enviados)

---

## âš™ï¸ ConfiguraÃ§Ã£o dos Endpoints

Os testes usam variÃ¡veis que podem ser alteradas diretamente nos arquivos `.jmx` ou via linha de comando:

| VariÃ¡vel | PadrÃ£o | DescriÃ§Ã£o |
|----------|--------|-----------|
| `BASE_URL` / `FE_URL` | localhost | Host da aplicaÃ§Ã£o |
| `PORT` / `FE_PORT` | 8080 / 80 | Porta da aplicaÃ§Ã£o |
| `API_URL` | localhost | Host da API (para teste C) |
| `API_PORT` | 8080 | Porta da API (para teste C) |
| `PROTOCOL` | http | Protocolo (http/https) |

### Alterando via Linha de Comando

```powershell
& "$env:JMETER_HOME\bin\jmeter.bat" -n -t teste_a_post_jwt.jmx `
    -JBASE_URL=192.168.1.100 `
    -JPORT=3000 `
    -l results.jtl -e -o dashboard
```

---

## ğŸ“ Requisitos do Ambiente Local

### Para Teste A e B (API)
- API Backend rodando em `localhost:8080`
- Endpoints REST disponÃ­veis

### Para Teste C (Frontend)
- **IMPORTANTE:** O Frontend deve estar rodando via **Nginx**, nÃ£o via Node.js
- Nginx servindo arquivos estÃ¡ticos na porta 80
- API Backend disponÃ­vel para chamadas AJAX

#### Exemplo de configuraÃ§Ã£o Nginx (nginx.conf):

```nginx
server {
    listen 80;
    server_name localhost;
    
    root /var/www/html;
    index index.html;
    
    location / {
        try_files $uri $uri/ /index.html;
    }
    
    location /api {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }
}
```

---

## ğŸ” Interpretando os Resultados

### MÃ©tricas Importantes

| MÃ©trica | Bom | AceitÃ¡vel | Ruim |
|---------|-----|-----------|------|
| Response Time (Avg) | < 200ms | 200-500ms | > 500ms |
| Error % | 0% | < 1% | > 1% |
| Throughput | > 100/sec | 50-100/sec | < 50/sec |

### GrÃ¡ficos do Dashboard

1. **Response Times Over Time** - Mostra a evoluÃ§Ã£o do tempo de resposta
2. **Throughput** - RequisiÃ§Ãµes processadas por segundo
3. **Response Time Percentiles** - DistribuiÃ§Ã£o dos tempos de resposta
4. **Errors** - Taxa de erros ao longo do tempo

---

## ğŸ‘¥ Grupo 8 - PI

- Projeto de anÃ¡lise de vendas de livros
- Testes de performance para validar escalabilidade
- Ambiente: AWS + Terraform + ECS
